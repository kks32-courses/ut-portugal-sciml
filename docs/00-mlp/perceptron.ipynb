{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 1D Poisson Equation\n",
    "\n",
    "We examine the one-dimensional Poisson equation on the unit interval $[0, 1]$ with homogeneous Dirichlet boundary conditions:\n",
    "\n",
    "$$-\\frac{d^2u}{dx^2} = f(x), \\quad x \\in [0, 1]$$\n",
    "\n",
    "subject to boundary conditions:\n",
    "$$u(0) = 0, \\quad u(1) = 0$$\n",
    "\n",
    "This equation models diverse physical phenomena: heat conduction in a rod, deflection of a loaded beam, or electrostatic potential in one dimension. The function $u(x)$ represents the unknown solution we seek, while $f(x)$ is the prescribed source term.\n",
    "\n",
    "For our initial exploration, we choose:\n",
    "$$f(x) = \\pi^2 \\sin(\\pi x)$$\n",
    "\n",
    "This choice is deliberate—it yields the analytical solution:\n",
    "$$u(x) = \\sin(\\pi x)$$\n",
    "\n",
    "We can verify this solution by direct substitution. The second derivative of $u(x) = \\sin(\\pi x)$ is $u''(x) = -\\pi^2 \\sin(\\pi x)$, so:\n",
    "$$-\\frac{d^2u}{dx^2} = -(-\\pi^2 \\sin(\\pi x)) = \\pi^2 \\sin(\\pi x) = f(x) \\quad \\checkmark$$\n",
    "\n",
    "The boundary conditions are satisfied: $u(0) = \\sin(0) = 0$ and $u(1) = \\sin(\\pi) = 0$ ✓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Set up plotting style for clarity\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'figure.figsize': (12, 8),\n",
    "    'lines.linewidth': 2.5,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3\n",
    "})\n",
    "\n",
    "# Define the domain\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "# Define the analytical solution and source function\n",
    "def analytical_solution(x):\n",
    "    \"\"\"Analytical solution: u(x) = sin(π*x)\"\"\"\n",
    "    return np.sin(np.pi * x)\n",
    "\n",
    "def source_function(x):\n",
    "    \"\"\"Source function: f(x) = π²*sin(π*x)\"\"\"\n",
    "    return np.pi**2 * np.sin(np.pi * x)\n",
    "\n",
    "# Compute solutions\n",
    "u_analytical = analytical_solution(x)\n",
    "f_source = source_function(x)\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot the analytical solution\n",
    "ax1.plot(x, u_analytical, 'b-', linewidth=3, label=r'$u(x) = \\sin(\\pi x)$')\n",
    "ax1.fill_between(x, 0, u_analytical, alpha=0.2, color='blue')\n",
    "ax1.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "ax1.plot([0, 0], [0, 0], 'ro', markersize=8, label='Boundary: u(0)=0')\n",
    "ax1.plot([1, 1], [0, 0], 'ro', markersize=8, label='Boundary: u(1)=0')\n",
    "ax1.set_xlabel('Position x')\n",
    "ax1.set_ylabel('Solution u(x)')\n",
    "ax1.set_title('Analytical Solution of 1D Poisson Equation', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot the source function\n",
    "ax2.plot(x, f_source, 'r-', linewidth=3, label=r'$f(x) = \\pi^2 \\sin(\\pi x)$')\n",
    "ax2.fill_between(x, 0, f_source, alpha=0.2, color='red')\n",
    "ax2.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n",
    "ax2.set_xlabel('Position x')\n",
    "ax2.set_ylabel('Source f(x)')\n",
    "ax2.set_title('Source Function', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Maximum value of solution: {np.max(u_analytical):.4f}\")\n",
    "print(f\"Maximum value of source: {np.max(f_source):.4f}\")\n",
    "print(f\"Solution satisfies boundary conditions: u(0) = {analytical_solution(0):.6f}, u(1) = {analytical_solution(1):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sparse training data\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "n_training_points = 10\n",
    "x_train = np.linspace(0, 1, n_training_points)\n",
    "u_train = analytical_solution(x_train)\n",
    "\n",
    "# Add small amount of noise to make it more realistic\n",
    "noise_level = 0.02\n",
    "u_train_noisy = u_train + noise_level * np.random.randn(n_training_points)\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot the true function\n",
    "x_fine = np.linspace(0, 1, 1000)\n",
    "u_true = analytical_solution(x_fine)\n",
    "ax.plot(x_fine, u_true, 'b-', linewidth=3, label='True Function: $u(x) = \\sin(\\pi x)$', alpha=0.7)\n",
    "\n",
    "# Plot training data\n",
    "ax.plot(x_train, u_train, 'ro', markersize=10, label=f'Exact Training Data ({n_training_points} points)', markeredgecolor='darkred')\n",
    "ax.plot(x_train, u_train_noisy, 'go', markersize=8, label=f'Noisy Training Data (σ={noise_level})', markeredgecolor='darkgreen')\n",
    "\n",
    "# Add some visual elements to emphasize the challenge\n",
    "for i, (xi, ui) in enumerate(zip(x_train, u_train_noisy)):\n",
    "    ax.axvline(x=xi, color='gray', linestyle='--', alpha=0.3, linewidth=1)\n",
    "    if i < len(x_train) - 1:\n",
    "        ax.fill_betweenx([0, 1.2], xi, x_train[i+1], alpha=0.1, color='orange')\n",
    "\n",
    "ax.set_xlabel('Position x', fontsize=14)\n",
    "ax.set_ylabel('Function Value u(x)', fontsize=14)\n",
    "ax.set_title('Function Approximation Challenge: Learning from Sparse Data', fontsize=16, fontweight='bold')\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(-0.2, 1.2)\n",
    "\n",
    "# Add annotation\n",
    "ax.annotate('How can we reconstruct\\nthe smooth function\\nfrom these few points?', \n",
    "            xy=(0.7, 0.8), xytext=(0.75, 0.4),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "            fontsize=12, ha='center',\n",
    "            bbox=dict(boxstyle='round,pad=0.3', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Challenge: Approximate a continuous function using only {n_training_points} data points\")\n",
    "print(f\"Training points spacing: {x_train[1] - x_train[0]:.3f}\")\n",
    "print(f\"We need to learn the pattern and interpolate smoothly between points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional vs Neural Network Approaches\n",
    "\n",
    "Traditional numerical methods for solving the 1D Poisson equation include:\n",
    "\n",
    "### Finite Difference Method\n",
    "Discretize the derivative using finite differences:\n",
    "$$\\frac{d^2u}{dx^2} \\approx \\frac{u_{i+1} - 2u_i + u_{i-1}}{h^2}$$\n",
    "\n",
    "This transforms the differential equation into a system of linear equations.\n",
    "\n",
    "### Finite Element Method\n",
    "Approximate the solution using basis functions (typically piecewise polynomials) and minimize the residual in a weak sense.\n",
    "\n",
    "### Neural Network Approach\n",
    "Represent the solution as:\n",
    "$$u_{NN}(x; \\theta) = \\text{Neural Network}(x; \\theta)$$\n",
    "\n",
    "where $\\theta$ represents the network parameters (weights and biases).\n",
    "\n",
    "Let's compare these approaches conceptually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple finite difference solution for comparison\n",
    "def solve_poisson_fd(n_points=51):\n",
    "    \"\"\"Solve 1D Poisson equation using finite differences\"\"\"\n",
    "    # Create grid\n",
    "    x_fd = np.linspace(0, 1, n_points)\n",
    "    h = x_fd[1] - x_fd[0]\n",
    "    \n",
    "    # Create coefficient matrix A for -u'' = f\n",
    "    # Central difference: u''_i ≈ (u_{i+1} - 2u_i + u_{i-1})/h²\n",
    "    A = np.zeros((n_points-2, n_points-2))\n",
    "    for i in range(n_points-2):\n",
    "        A[i, i] = -2.0 / h**2\n",
    "        if i > 0:\n",
    "            A[i, i-1] = 1.0 / h**2\n",
    "        if i < n_points-3:\n",
    "            A[i, i+1] = 1.0 / h**2\n",
    "    \n",
    "    # Right-hand side (source function at interior points)\n",
    "    f_rhs = source_function(x_fd[1:-1])\n",
    "    \n",
    "    # Solve linear system\n",
    "    u_interior = np.linalg.solve(-A, f_rhs)  # Note: -A because we have -u'' = f\n",
    "    \n",
    "    # Assemble full solution (including boundary conditions)\n",
    "    u_fd = np.zeros(n_points)\n",
    "    u_fd[1:-1] = u_interior\n",
    "    u_fd[0] = 0  # u(0) = 0\n",
    "    u_fd[-1] = 0  # u(1) = 0\n",
    "    \n",
    "    return x_fd, u_fd\n",
    "\n",
    "# Solve using finite differences with different resolutions\n",
    "x_fd_coarse, u_fd_coarse = solve_poisson_fd(11)  # Coarse grid\n",
    "x_fd_fine, u_fd_fine = solve_poisson_fd(51)      # Fine grid\n",
    "\n",
    "# Create comparison plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Method comparison\n",
    "x_exact = np.linspace(0, 1, 1000)\n",
    "u_exact = analytical_solution(x_exact)\n",
    "\n",
    "ax1.plot(x_exact, u_exact, 'k-', linewidth=3, label='Analytical Solution', alpha=0.8)\n",
    "ax1.plot(x_fd_coarse, u_fd_coarse, 'ro-', linewidth=2, markersize=6, label='Finite Difference (Coarse)', alpha=0.8)\n",
    "ax1.plot(x_fd_fine, u_fd_fine, 'b.-', linewidth=1, markersize=4, label='Finite Difference (Fine)', alpha=0.8)\n",
    "ax1.scatter(x_train, u_train_noisy, color='green', s=80, label='Neural Network Training Data', \n",
    "           edgecolors='darkgreen', linewidth=2, zorder=5)\n",
    "\n",
    "ax1.set_xlabel('Position x')\n",
    "ax1.set_ylabel('Solution u(x)')\n",
    "ax1.set_title('Comparison of Solution Methods', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Error analysis\n",
    "error_coarse = np.abs(u_fd_coarse - analytical_solution(x_fd_coarse))\n",
    "error_fine = np.abs(u_fd_fine - analytical_solution(x_fd_fine))\n",
    "\n",
    "ax2.semilogy(x_fd_coarse, error_coarse, 'ro-', linewidth=2, markersize=6, label='Coarse Grid Error')\n",
    "ax2.semilogy(x_fd_fine, error_fine, 'b.-', linewidth=1, markersize=4, label='Fine Grid Error')\n",
    "ax2.set_xlabel('Position x')\n",
    "ax2.set_ylabel('Absolute Error (log scale)')\n",
    "ax2.set_title('Discretization Error Analysis', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print error statistics\n",
    "print(f\"Finite Difference Error Statistics:\")\n",
    "print(f\"Coarse grid (11 points): Max error = {np.max(error_coarse):.6f}\")\n",
    "print(f\"Fine grid (51 points):   Max error = {np.max(error_fine):.6f}\")\n",
    "print(f\"Error reduction factor: {np.max(error_coarse)/np.max(error_fine):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Function Approximation Challenge\n",
    "\n",
    "Consider this question: *Can a neural network learn to approximate $u(x) = \\sin(\\pi x)$ by observing only sparse data points?*\n",
    "\n",
    "Let's explore this with a concrete example. Unlike traditional numerical method, which learns a discrete representation of the function. A neural network aims to learn a continous function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
